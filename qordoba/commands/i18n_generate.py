from i18n_base import get_files_in_dir_with_subdirs, ignore_files
import pandas as pd
import requests

def get_key(value):
	r = requests.post('https://qordoba-devel.appspot.com/convert', data = {'text': value})
	keywords = r.json()["keywords"]
	key = '.'.join(keywords)
	return key

def generate(_curdir, input=None, output=None, existing_i18nfiles=None):
	""" Given localization files exists, gives back existing keys.
	Further, generating new keys for values
	"""
	report_files = get_files_in_dir_with_subdirs(input)
	report_files = ignore_files(report_files)
	for single_report_path in report_files:
		print("HEYHEYHEY")
		"""
	    Validate report
	    """
		if not single_report_path.endswith(".json"):
			continue

		df = pd.read_json(single_report_path)
		print(df[0])

		# df.text = (df.text).apply(lambda x: self.strip_qoutes(x))

		# # lookup if stringliteral exists as value or key in a localization file.. If yes, return key, otherwise None.
		# localization_file_list = config.exsisting_i18n

		# if localization_file_list:
		#     df = self.get_existing_keys(localization_file_list, df)

		# log.info(
		#     "  " + u"\U0001F4AB" + u"\U0001F52E" + " .. starting to generate new keys for you - based on the extracted Strings from your files.")
		# log.info(" (This could Take some time)")
		# log.info("\b")

		# # New keys are generated by picking the two lowest frequence word of english corpus within given string
		# df['generated_keys'] = (df.text).apply(lambda x: self.generate_new_keys(x))
		# os.remove(single_report_path)
		# df.to_json(single_report_path, encoding='utf-8', index=False)
		# log.info("Process completed. " + u"\U0001F680" + u"\U0001F4A5")
